{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import tensorflow.keras as keras\n",
    "import glob\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('../data/train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = 2500\n",
    "VAL_LENGTH = 500\n",
    "IMAGE_SIZE = (128, 128)\n",
    "INPUT_SHAPE = (3000, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x = Image.open(filenames[i])\n",
    "    x = x.resize(IMAGE_SIZE)\n",
    "    plt.imshow(x)\n",
    "    plt.title(filenames[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEncoder(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "                layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "                layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "                layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', activation='relu')\n",
    "                ])\n",
    "        \n",
    "        self.fe_down = layers.Conv2D(filters=out_channels, kernel_size=kernel_size, strides=2, padding='same',\n",
    "                                            activation='relu')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        f = x\n",
    "        x = self.fe_down(x)\n",
    "        return f, x\n",
    "    \n",
    "class FeatureDecoder(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size):\n",
    "        super(FeatureDecoder, self).__init__()\n",
    "        self.de_up = layers.Conv2DTranspose(filters=out_channels, kernel_size=kernel_size, strides=2, \n",
    "                                             padding='same', output_padding=1)\n",
    "        \n",
    "        self.conv_first = layers.Conv2D(filters=out_channels, kernel_size=1, padding='same', activation='relu')\n",
    "        self.conv = keras.Sequential([\n",
    "                layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "                layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "                layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', activation='relu')\n",
    "            ])\n",
    "        self.conv_last = layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same')\n",
    "\n",
    "    def call(self, x, down_tensor):\n",
    "        x = self.de_up(x)\n",
    "        \n",
    "        # Calculate cropping for down_tensor to concatenate with x\n",
    "        _, h2, w2, _ = down_tensor.shape\n",
    "        _, h1, w1, _ = x.shape\n",
    "        h_diff, w_diff = h2 - h1, w2 - w1\n",
    "        \n",
    "        cropping = ((int(np.ceil(h_diff / 2)), int(np.floor(h_diff / 2))),\n",
    "                    (int(np.ceil(w_diff / 2)), int(np.floor(w_diff / 2))))\n",
    "        down_tensor = layers.Cropping2D(cropping=cropping)(down_tensor)        \n",
    "        x = layers.concatenate([x, down_tensor], axis=3)\n",
    "        \n",
    "        x = self.conv_first(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPDNN(Model):\n",
    "    def __init__(self):\n",
    "        super(DPDNN, self).__init__()\n",
    "        self.fe1 = FeatureEncoder(out_channels=64, kernel_size=3)\n",
    "        self.fe2 = FeatureEncoder(out_channels=64, kernel_size=3)\n",
    "        self.fe3 = FeatureEncoder(out_channels=64, kernel_size=3)\n",
    "        self.fe4 = FeatureEncoder(out_channels=64, kernel_size=3)\n",
    "        self.fe_end = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')\n",
    "        \n",
    "        self.de4 = FeatureDecoder(out_channels=64, kernel_size=3)\n",
    "        self.de3 = FeatureDecoder(out_channels=64, kernel_size=3)\n",
    "        self.de2 = FeatureDecoder(out_channels=64, kernel_size=3)\n",
    "        self.de1 = FeatureDecoder(out_channels=64, kernel_size=3)\n",
    "        self.de_end = layers.Conv2D(filters=1, kernel_size=3, padding='same')\n",
    "        \n",
    "        # Defining learnable parameters\n",
    "        self.delta_1 = tf.Variable(0.1, trainable=True)\n",
    "        self.eta_1 = tf.Variable(0.9, trainable=True)\n",
    "        \n",
    "        self.delta_2 = tf.Variable(0.1, trainable=True)\n",
    "        self.eta_2 = tf.Variable(0.9, trainable=True)\n",
    "        \n",
    "        self.delta_3 = tf.Variable(0.1, trainable=True)\n",
    "        self.eta_3 = tf.Variable(0.9, trainable=True)\n",
    "        \n",
    "        self.delta_4 = tf.Variable(0.1, trainable=True)\n",
    "        self.eta_4 = tf.Variable(0.9, trainable=True)\n",
    "        \n",
    "        self.delta_5 = tf.Variable(0.1, trainable=True)\n",
    "        self.eta_5 = tf.Variable(0.9, trainable=True)\n",
    "        \n",
    "        self.delta_6 = tf.Variable(0.1, trainable=True)\n",
    "        self.eta_6 = tf.Variable(0.9, trainable=True)\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        \n",
    "        for i in range(6):\n",
    "            f1, out = self.fe1(x)\n",
    "            f2, out = self.fe2(out)\n",
    "            f3, out = self.fe3(out)\n",
    "            f4, out = self.fe4(out)\n",
    "            out = self.fe_end(out)\n",
    "\n",
    "            out = self.de4(out, f4)\n",
    "            out = self.de3(out, f3)\n",
    "            out = self.de2(out, f2)\n",
    "            out = self.de1(out, f1)\n",
    "            v = self.de_end(out)\n",
    "\n",
    "            v = v + x\n",
    "            x = self.reconnect(v, x, y, i)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def reconnect(self, v, x, y, i):\n",
    "        i = i + 1\n",
    "        if i == 1:\n",
    "            delta = self.delta_1\n",
    "            eta = self.eta_1\n",
    "        if i == 2:\n",
    "            delta = self.delta_2\n",
    "            eta = self.eta_2\n",
    "        if i == 3:\n",
    "            delta = self.delta_3\n",
    "            eta = self.eta_3\n",
    "        if i == 4:\n",
    "            delta = self.delta_4\n",
    "            eta = self.eta_4\n",
    "        if i == 5:\n",
    "            delta = self.delta_5\n",
    "            eta = self.eta_5\n",
    "        if i == 6:\n",
    "            delta = self.delta_6\n",
    "            eta = self.eta_6\n",
    "        \n",
    "        recon = tf.multiply((1 - delta - eta), v) + tf.multiply(eta, x) + tf.multiply(delta, y)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_pair(filename):\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize(IMAGE_SIZE)\n",
    "    y = np.array(im)\n",
    "    y_min, y_max = np.min(y), np.max(y)\n",
    "    y_normalized = (y - y_min) / (y_max - y_min)\n",
    "\n",
    "    blur_radius = np.random.uniform(1, 5)\n",
    "    blurred_im = im.filter(ImageFilter.GaussianBlur(blur_radius))\n",
    "    x = np.array(blurred_im)\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    x_normalized = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "    return (x_normalized, y_normalized)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(filenames):\n",
    "    random.shuffle(filenames)\n",
    "    dataset = list(map(_generate_pair, filenames))\n",
    "    x_train, y_train = zip(*dataset)\n",
    "    return np.array(x_train), np.array(y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_datasets(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "\n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "    \n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][np.newaxis, ...])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1].astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "import datetime\n",
    "log_dir=os.path.join('logs', 'fit') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=1000000)\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "plot_image_tensorboard_cb = keras.callbacks.LambdaCallback(on_epoch_end=plot_image_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DPDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "STEPS_PER_EPOCH = 3000 // BATCH_SIZE\n",
    "VAL_STEPS = VAL_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "model.build(INPUT_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample = (x_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=400, batch_size=8, validation_split=0.1, \n",
    "          callbacks=[plot_image_tensorboard_cb, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "a = model.predict(x_train[np.newaxis, i, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dpdnn",
   "language": "python",
   "name": "venv-dpdnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
